{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256,\n",
      " 'cifar_dir': '../data/cifar',\n",
      " 'config_dir': '../configs',\n",
      " 'learning_rate': 0.05,\n",
      " 'metrics': ['IGS'],\n",
      " 'models_dir': '../models',\n",
      " 'momentum': 0.9,\n",
      " 'num_epochs': 75,\n",
      " 'seed': [43, 91, 17],\n",
      " 'sharpness_batch_size': 36,\n",
      " 'sharpness_dataset_size': 750,\n",
      " 'vgg_config': 'vgg_config.json',\n",
      " 'wandb': {'entity': 'r252_project',\n",
      "           'experiment_name': '',\n",
      "           'project': 'VGG19_CIFAR100_FINAL'}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "from data_loader_manager import dataloaders\n",
    "from models import vgg_model\n",
    "from trainers.metrics_processor import MetricsProcessor\n",
    "\n",
    "with open(\"../configs/igs_config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "pprint(config)\n",
    "\n",
    "config = EasyDict(config)\n",
    "config.aug = False\n",
    "config.adversarial = False\n",
    "\n",
    "config.sharpness_batch_size = 16\n",
    "config.sharpness_dataset_size = 128*10\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = vgg_model.VGG(\n",
    "    vgg_name=\"VGG19\",\n",
    "    dropout=0.0,\n",
    "    vgg_config=Path(config.config_dir) / config.vgg_config,\n",
    "    num_classes=10\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"../models/CIFAR10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/CIFAR10/baseline/91/best_baseline.pth\n",
      "Loading normal train data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]/rds/user/is473/hpc-work/R252_Group_Project/src/trainers/igs/igs.py:1329: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  y_F = torch.cuda.LongTensor([i]*output.shape[0])\n",
      "  0%|          | 0/80 [00:05<?, ?it/s]\n",
      "/rds/user/is473/hpc-work/R252_Group_Project/src/trainers/metrics_processor.py:189: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert i is not -1\n",
      "/rds/user/is473/hpc-work/R252_Group_Project/src/trainers/metrics_processor.py:189: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert i is not -1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     16\u001b[0m mp \u001b[38;5;241m=\u001b[39m MetricsProcessor(\n\u001b[1;32m     17\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mdata_loader_manager\u001b[38;5;241m.\u001b[39mnum_classes\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m igs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIGS\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(igs)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(igs\u001b[38;5;241m.\u001b[39mmean(), igs\u001b[38;5;241m.\u001b[39mstd())\n",
      "File \u001b[0;32m/rds/user/is473/hpc-work/R252_Group_Project/src/trainers/metrics_processor.py:393\u001b[0m, in \u001b[0;36mMetricsProcessor.IGS\u001b[0;34m(self, output_all)\u001b[0m\n\u001b[1;32m    391\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m#experiment_fast(model, False, X,y,criterion, criterion_alldata)\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m IGS_dims, L, V, spurious_dim \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_IGS_largemodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mexact_fisher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(IGS_dims)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    395\u001b[0m     IGS\u001b[38;5;241m.\u001b[39mappend(IGS_dims[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/rds/user/is473/hpc-work/R252_Group_Project/src/trainers/igs/igs.py:1329\u001b[0m, in \u001b[0;36mcalculate_IGS_largemodel\u001b[0;34m(model, X_F, X, y, criterion, tol, top_n, exact_fisher, eps, expand)\u001b[0m\n\u001b[1;32m   1327\u001b[0m trF \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m-> 1329\u001b[0m     y_F \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m     Js\u001b[38;5;241m.\u001b[39mappend(calculate_jacobian_wrt_params_alldata_dataloader(model, X_F, y_F, criterion))\n\u001b[1;32m   1331\u001b[0m     trF \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((ps[:,i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m*\u001b[39mJs[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m X_F\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/rds/hpc-work/R252_Group_Project/r252-env/lib/python3.8/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for model_path in glob.glob(f\"{str(model_dir)}/*/*/best_baseline*.pth\"):\n",
    "  print(model_path)\n",
    "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "  data_loader_manager = dataloaders.DataLoaderManager(\n",
    "      config=config,\n",
    "      dataset_name=\"CIFAR10\",\n",
    "      seed=seed,\n",
    "  )\n",
    "\n",
    "  train_dataloader, dev_dataloader, test_dataloader, sharpness_dataloader = data_loader_manager.get_dataloaders()\n",
    "\n",
    "  model.eval()\n",
    "  mp = MetricsProcessor(\n",
    "      config=config,\n",
    "      model=model,\n",
    "      train_dataloader=sharpness_dataloader,\n",
    "      test_dataloader=sharpness_dataloader,\n",
    "      model_name=\"\",\n",
    "      device=device,\n",
    "      seed=seed,\n",
    "      num_classes=data_loader_manager.num_classes\n",
    "  )\n",
    "\n",
    "  igs = np.log(mp.IGS(output_all=True))\n",
    "  print(igs)\n",
    "  print(igs.mean(), igs.std())\n",
    "\n",
    "  with (model_dir / \"igs_output\").open(\"a\") as logfile:\n",
    "      logfile.write(f\"{model_path},{igs.mean()},{igs.std()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
